{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Prototyping Grounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic webpage scraping with selenium\n",
    "\n",
    "Selenium is a web automation tool that allows you to automate interactions with websites.\n",
    "\n",
    "Chromedriver is a web driver that allows you to automate interactions with websites.\n",
    "\n",
    "The target website is [FeverDreams](https://www.feverdreams.app/recent/1). Feverdreams.app is a site that allows you to browse and create AI-generated artwork.\n",
    "\n",
    "### Create functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code first to set up the scraper.\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import json, uuid\n",
    "from json import JSONDecodeError\n",
    "from pathlib import Path\n",
    "import html\n",
    "import wget\n",
    "\n",
    "PATH = \"F:\\\\\" \n",
    "START = \"https://www.feverdreams.app/recent/1\"\n",
    "TARGET_LIST = []\n",
    "DATA_DICT = { \"creations\" : [] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_UUID():\n",
    "    return str(uuid.uuid4())\n",
    "\n",
    "mlva_uuid = get_UUID()\n",
    "\n",
    "def get_public_metadata(source_json, identifier):\n",
    "    key_list = [\n",
    "        \"transformation_percent\",\n",
    "        \"clip_models_schedules\",\n",
    "        \"diffusion_model_config\",\n",
    "        \"width_height\",\n",
    "        \"clip_guidance_scale\",\n",
    "        \"skip_event\",\n",
    "        \"sat_scale\",\n",
    "        \"batch_name\",\n",
    "        \"name_docarray\",\n",
    "        \"cut_innercut\",\n",
    "        \"skip_augs\",\n",
    "        \"clip_denoised\",\n",
    "        \"seed\",\n",
    "        \"use_vertical_symmetry\",\n",
    "        \"init_scale\",\n",
    "        \"steps\",\n",
    "        \"use_secondary_model\",\n",
    "        \"text_prompts\",\n",
    "        \"gif_fps\",\n",
    "        \"cut_icgray_p\",\n",
    "        \"truncate_overlength_prompt\",\n",
    "        \"clip_models\",\n",
    "        \"cut_overview\",\n",
    "        \"display_rate\",\n",
    "        \"use_horizontal_symmetry\",\n",
    "        \"eta\",\n",
    "        \"perlin_init\",\n",
    "        \"init_image\",\n",
    "        \"clamp_max\",\n",
    "        \"randomize_class\",\n",
    "        \"on_misspelled_token\",\n",
    "        \"gif_size_ratio\",\n",
    "        \"save_rate\",\n",
    "        \"rand_mag\",\n",
    "        \"range_scale\",\n",
    "        \"tv_scale\",\n",
    "        \"n_batches\",\n",
    "        \"cut_ic_pow\",\n",
    "        \"clamp_grad\",\n",
    "        \"batch_size\",\n",
    "        \"stop_event\",\n",
    "        \"text_clip_on_cpu\",\n",
    "        \"diffusion_sampling_mode\",\n",
    "        \"diffusion_model\",\n",
    "        \"cutn_batches\",\n",
    "        \"cut_schedules_group\",\n",
    "        \"skip_steps\",\n",
    "        \"perlin_mode\"\n",
    "    ]\n",
    "\n",
    "    \n",
    "    public_metadata = {\n",
    "        \"mlva_uuid\" : identifier,\n",
    "        \"piece_metadata\": []\n",
    "    }\n",
    "\n",
    "    with open(source_json, \"r\", encoding='utf-8') as f:\n",
    "        metadata = json.load(f)\n",
    "        \n",
    "    for key in metadata['discoart_tags']:\n",
    "        if key in key_list:\n",
    "            try:\n",
    "                public_metadata['piece_metadata'].append(f\"{key}={metadata[key]}\")\n",
    "            except KeyError:\n",
    "                public_metadata['piece_metadata'].append(f\"{key}=Null\")\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    return public_metadata\n",
    "\n",
    "def get_private_metadata(source_json, identifier):\n",
    "    \n",
    "    private_metadata = {\n",
    "        \"mlva_uuid\" : identifier,\n",
    "        \"piece_metadata\": []\n",
    "    }\n",
    "\n",
    "    with open(source_json, \"r\", encoding='utf-8') as f:\n",
    "        metadata = json.load(f)\n",
    "        \n",
    "    for key in metadata:\n",
    "        try:\n",
    "            private_metadata['piece_metadata'].append(f\"{key}={metadata[key]}\")\n",
    "        except KeyError:\n",
    "            private_metadata['piece_metadata'].append(f\"{key}=Null\")\n",
    "\n",
    "    return private_metadata\n",
    "\n",
    "\n",
    "def url_to_json(url:str, driver:webdriver)->str:\n",
    "    \"\"\"\n",
    "    define a function called 'url_to_json' that takes in a url and a driver. The function should:\n",
    "    1. It should take the driver and point it at the url.\n",
    "    2. it should load the page and wait for the page to load.\n",
    "    3. It should load the entire contents of the page into a json string.\n",
    "    \"\"\"\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    page_source = driver.find_element(By.TAG_NAME, \"body\").get_attribute(\"innerHTML\")\n",
    "    time.sleep(10)\n",
    "    with open(\"F:\\dogma\\CentralDogma\\MechArtResearch\\MechPromptFinder\\src\\metadata_cache.json\", \"w+\", encoding='utf-8') as f:\n",
    "        print(page_source, file=f)\n",
    "    return \"F:\\dogma\\CentralDogma\\MechArtResearch\\MechPromptFinder\\src\\metadata_cache.json\"\n",
    "\n",
    "def url_to_metadata_url(url:str)->str:\n",
    "    \"\"\"\n",
    "    define a function called 'url_to_metadata_url' that takes in a url and returns a url to the metadata.\n",
    "    \"\"\"\n",
    "    return url.replace(\"/piece/\", \"/job/\").replace(\"www\", \"api\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Pulldown Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(PATH + \"chromedriver.exe\")\n",
    "\n",
    "\n",
    "test_result = get_public_metadata(url_to_json(\"https://api.feverdreams.app/job/a247fcea-80e9-4e5b-9895-016031a7a297\", driver))\n",
    "print(test_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Elements Of Working With Selenium\n",
    "\n",
    "```python\n",
    "def create_target_archive(driver_path, current_page:str)->list:\n",
    "    \"\"\"\n",
    "    Define a function called create_target_archive that takes a driver, a current page, a next page and a target list. The function should:\n",
    "    1. It should create a webdriver called 'driver' and point it at the current page.\n",
    "    2. Find and create a list called 'browse_list' of urls in the href attributes of all 'a' elements that are children of 'div' elements.\n",
    "    3. It should create a dictionary called 'results_dict' with the keys 'next_page' with the value browse_list[1] and 'new_targets' with browse_list[2:-7].\n",
    "    4. It should call driver.quit() and sleep for 5 seconds.\n",
    "    5. It should return results_dict.\n",
    "    \"\"\"\n",
    "    driver = webdriver.Chrome(driver_path + \"chromedriver.exe\")\n",
    "    driver.get(current_page)\n",
    "    time.sleep(15)\n",
    "    browse_list = href_list(driver.find_elements(By.XPATH, \"//div/a[@href]\"))\n",
    "    results_dict = { \"next_page\" : browse_list[1], \"new_targets\" : browse_list[2:-7] }\n",
    "    time.sleep(5)\n",
    "    driver.quit()\n",
    "    return results_dict  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Pulldown Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_piece(url:str, driver_path:str)->str:\n",
    "    driver = webdriver.Chrome(driver_path + \"chromedriver.exe\")\n",
    "    driver.get(url)\n",
    "    time.sleep(10)\n",
    "    identifier = driver.find_elements(By.XPATH, \"//div/h4\")[0].text,\n",
    "    print(f\"Identifier is type {type(identifier)} --> {identifier}\")\n",
    "    img_src = driver.find_elements(By.XPATH, \"//a/img\")[0].get_attribute(\"src\"),\n",
    "    image_path = f\"F:\\dogma\\CentralDogma\\MechArtResearch\\MechPromptFinder\\src\\data\\images\\{identifier[0]}.png\"\n",
    "    driver.find_elements(By.XPATH, \"//a/img\")[0].screenshot(image_path)\n",
    "    prompt = driver.find_elements(By.XPATH, \"//div/code\")[0].text,\n",
    "    public_metadata = get_public_metadata(url_to_json(url_to_metadata_url(url), driver), mlva_uuid),\n",
    "    private_metadata = get_private_metadata(url_to_json(url_to_metadata_url(url), driver), mlva_uuid),\n",
    "    piece_cache = {\n",
    "        \"identifier\":identifier,\n",
    "        \"img_src\": img_src,\n",
    "        \"prompt\": prompt,\n",
    "        \"public_metadata\": public_metadata,\n",
    "        \"private_metadata\": private_metadata,\n",
    "    }\n",
    "\n",
    "    time.sleep(10)\n",
    "    driver.quit()\n",
    "    image_dest = Path(image_path)\n",
    "    if Path.is_file(image_dest):\n",
    "        print(f\"Download of image: {img_src} to {image_path} completed.\")\n",
    "    else:\n",
    "        print(f\"Download of image: {img_src} to {image_path} may have failed.\")\n",
    "    output_file = f\"data/feverdream__scrape/{identifier[0]}.json\"\n",
    "    with open(output_file, \"w\", encoding='utf-8') as f:\n",
    "        json.dump(piece_cache, f, indent=4)\n",
    "    return output_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Pulldown Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\exx\\AppData\\Local\\Temp\\ipykernel_19004\\3787829596.py:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(driver_path + \"chromedriver.exe\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifier is type <class 'tuple'> --> ('b2ebc94f-f199-4699-bf53-814e5ca7da15',)\n",
      "Download of image: ('http://images.feverdreams.app/jpg/b2ebc94f-f199-4699-bf53-814e5ca7da15.jpg',) to F:\\dogma\\CentralDogma\\MechArtResearch\\MechPromptFinder\\src\\data\\images\\b2ebc94f-f199-4699-bf53-814e5ca7da15.png completed.\n",
      "data/feverdream__scrape/b2ebc94f-f199-4699-bf53-814e5ca7da15.json\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.feverdreams.app/piece/b2ebc94f-f199-4699-bf53-814e5ca7da15\"\n",
    "\n",
    "result = scrape_piece(url, PATH)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.feverdreams.app/piece/b2ebc94f-f199-4699-bf53-814e5ca7da15\"\n",
    "driver = webdriver.Chrome(PATH + \"chromedriver.exe\")\n",
    "driver.get(url)\n",
    "identifier = \"b2ebc94f-f199-4699-bf53-814e5ca7da15\"\n",
    "img_src = \"http://images.feverdreams.app/jpg/b2ebc94f-f199-4699-bf53-814e5ca7da15.jpg\"\n",
    "image_path = f\"F:\\dogma\\CentralDogma\\MechArtResearch\\MechPromptFinder\\src\\data\\images\\{identifier}.jpg\"\n",
    "if Path.is_file(image_path):\n",
    "    print(f\"Download of image: {img_src} to {image_path} completed.\")\n",
    "else:\n",
    "    print(f\"Download of image: {img_src} to {image_path} may have failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6e3ccd5b55ee40211697f98cd26e5f67298f8dc455bfef5458cc049a7c5d720a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
